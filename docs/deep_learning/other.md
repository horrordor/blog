# **Neural Network**

卷积池化前后大小对比

输入大小: 

$$ W * W, kernel-size=F, stride=S, padding=P $$

输出大小: 

$$ N = \frac{W-F+2P}{S}+1 $$

# Dropout

一种正则化方法，用于防止深度神经网络过拟合，其主要思想是在训练过程中随机选择神经元进行忽略，从而可以减少神经元之间的依赖性，强制使网络更多地依靠其他神经元来进行预测

# Problem

为什么感觉这些著名的神经网络的设计具有一定的主观性，想设计几个卷积层就设计几个，也没有什么依据